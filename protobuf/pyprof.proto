syntax = "proto3";

package iml.pyprof;

// Q: This is the single binary-file output format.
// In reality, we only need to keep a single "step" in memory when profiling.
// Should keep that in mind if profiling memory overhead becomes an issue.
message Pyprof {
    // Traced steps.
    repeated int64 steps = 1;
    // For a given sampled step, the python start/stop times.
    // step -> List[ <start, stop>, ... ]
    map<int64, PythonEvents> python_events = 2;
    // For a given sampled step, the start/stop times for all the
    // different C-libraries that have been wrapped.
    // step ->
    //   Category name (e.g. "Framework API") -> [ <start, stop>, ... ]
    map<int64, CLibs> clibs = 3;

    string process_name = 4;
    string phase = 5;
}

// Metadata about a process.
// Only one of these files is written per-process, when the process exits.
// This captures information that not is not conveniently/efficiently captured by
// existing "profiling" files (i.e. Pyprof, ProfileProto)
// - Process dependency information:
//   information needed for visualizing the computational graph.
message ProcessMetadata {
    message ProcessChildren {
        repeated string process_name = 1;
    }
    // parent -> child:
    // On exit, a parent process will know all the child-processes it launched.
    // This map encode that information
    map<string, ProcessChildren> process_children = 1;
}

// Samples of "overall device utilization" for each device on this machine.
message MachineUtilization {
    // A unique cross-machine identifier (e.g. $(hostname)).
    string machine_name = 1;
    // device_name (e.g. CPU/GPU) -> utilization samples for that device
    map<string, DeviceUtilization> device_util = 2;
}
message DeviceUtilization {
    string device_name = 1;
    repeated UtilizationSample samples = 2;
}
message UtilizationSample {
    // Epoch in usec when sample was taken.
    int64 start_time_us = 1;
    // Percent utilization: [0..100]
    float util = 2;
}

// Q: What unit of time should we use?
// Looks like tfprof already uses microseconds, so may as well do that.
message Event {
    int64 thread_id = 1;
    int64 start_time_us = 2;
    int64 duration_us = 3;
    string name = 4;
    // map<string, AttrValue> attrs = 5;
    map<string, string> attrs = 5;
}

message CLibs {
    // Category name (e.g. "Framework API") -> [ <start, stop>, ... ]
    map<string, CLibEvents> clibs = 1;
}
message CLibEvents {
    repeated Event events = 1;
}

message PythonEvents {
    repeated Event events = 1;
}

message ListValue {
    repeated bytes s = 2;                        // "list(string)"
    repeated int64 i = 3 [packed = true];        // "list(int)"
    repeated float f = 4 [packed = true];        // "list(float)"
    repeated bool b = 5 [packed = true];         // "list(bool)"
}

// Taken from tensorflow
message AttrValue {
  oneof value {
    bytes s = 2;                 // "string"
    int64 i = 3;                 // "int"
    float f = 4;                 // "float"
    bool b = 5;                  // "bool"
    ListValue list = 1;          // any "list(...)"
  }
}

